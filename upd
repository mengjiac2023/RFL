from base64 import encode
from model import *
from context import Context
import time
from tqdm import tqdm
from party import Party 
from client import Client
from data_util import *
from util import *
from torch import nn
from torch.utils.data import DataLoader
from torch import optim
from torchvision.utils import save_image

def get_optimizer(model_params):
    return optim.SGD(model_params,lr=0.1)
def get_model():
    model = Classifier(input_layer=32*32*3)#SimpleConvNet(1,10)
    return model.to('cuda')

def load_model(state_dict, model):
    model.load_state_dict(state_dict)

def get_dataloader(self, batch_size):
    self.dataset = FedDataset(self.images, self.labels)
    self.data_loader = DataLoader(self.dataset,shuffle=True,batch_size=batch_size)

def train(self, local_iter):
    i = 0
    while i < local_iter:
        for img, lbl in self.data_loader:
            i+=1
            img = img.to('cuda')
            lbl = lbl.to('cuda')
            predict = self.model(img)
            loss= nn.CrossEntropyLoss()(predict, lbl)
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            # print(loss.item())
            # print(img.max())
            if i == local_iter:
                break
def encode_model(self):
    self.model_info = model_to_flatten_int_vector(self.model.state_dict(),2**19)
    msg = self.model_info['tensor']
    Party.ori_shape = msg.shape[0]
    # print(ori_shape)
    ideal_shape = (int(Party.ori_shape/ctx.degree)+1)*ctx.degree
    self.padded_msg = np.zeros(ideal_shape)
    self.padded_msg[:Party.ori_shape] = msg
def decode_model(self, decrypted=None):
    if decrypted is not None:
        self.model_info['tensor'] = decrypted
    model_state = flatten_int_vector_to_model(self.model_info,2**19)
    return model_state
    # print(model_state['fc3.bias'])
    # print(self.model.state_dict()['fc3.bias'])
    # load_model(model_state, self.model)
    # print(self.model.state_dict()['fc3.bias'])
    # print(self.model.parameters())

def encrypt_model(self):
    ciphertexts = self.encrypt_native(self.padded_msg)
    return ciphertexts
def decrypt_model(ciphertexts):
    fins = Party.decrypt_native(ciphertexts)
    fins = np.concatenate([to_numpy(fin.to_string()) for fin in fins])[:Party.ori_shape]
    return fins

Party.get_dataloader = get_dataloader
Party.train = train
Party.encode_model = encode_model
Party.decode_model = decode_model
Party.encrypt_model = encrypt_model
Party.decrypt_model = decrypt_model

# def get_data():

ctx = Context()
global_model = get_model()
evaluator= Evaluator(ctx.seal_context)
datasets, labels = share_data_mnist(ctx.n_party)
for i in tqdm(range(ctx.n_party)):
    p = Client(i+1, ctx)
    p.model = get_model()
    p.optimizer = get_optimizer(p.model.parameters())
    load_model(global_model.state_dict(), p.model)
    p.images = datasets[i]
    p.labels = labels[i]
    p.get_dataloader(ctx.local_batch_size)

for i in tqdm(range(ctx.n_server)):
    p = Party(i+1, ctx)
    # p.model = get_model()
    # p.optimizer = get_optimizer(p.model.parameters())
    # load_model(global_model.state_dict(), p.model)
    # p.images = datasets[i]
    # p.labels = labels[i]
    # p.get_dataloader(ctx.local_batch_size)

for p in tqdm(Party.parties):
    p.get_secret_share()

def secure_aggregation(party_indices):
    avg_time = 0
    t = time.time()
    all_ciphertexts = []
    for party_id in party_indices:
        p = Client.parties[party_id]
        p.encode_model()
        all_ciphertexts.append(p.encrypt_model())
    avg_time += (time.time()-t)/len(party_indices)
    t= time.time()
    ctx_total = [evaluator.add_many([ciphertext[i] for ciphertext in all_ciphertexts]) for i in range(len(all_ciphertexts[0]))]
    avg_time += time.time()-t
    t= time.time()
    final_dec = Party.decrypt_model(ctx_total)
    avg_time += (time.time()-t)/Party.context.t_threshold
    t = time.time()
    final_dec = p.decode_model(final_dec)
    load_model(final_dec,global_model)
    avg_time += time.time()-t
    return avg_time

Party.pubkeygen(ctx.t_threshold)
Client.broadcast_pk(Party.encryptor)
# Party.parties[0].train(1000)
# Party.parties[1].train(1000)
# secure_aggregation([0,1])
ppr = 30#ctx.n_party#1000
import random

def total_train(num_round):
    train_times=[]
    secagg_times=[]
    for i in range(num_round):
        joined = random.sample(range(ctx.n_party),ppr)
        t = time.time()
        for p_id in joined:
            party = Party.parties[p_id]
            # party.train(5)
        train_time = (time.time()-t)/ppr
        # t = time.time()
        
        secagg_time = secure_aggregation(joined)
        train_times.append(train_time)
        secagg_times.append(secagg_time)
    print("SA time:",sum(secagg_times)/num_round)
    print("FL+SA time:",sum(secagg_times)/num_round + sum(train_times)/num_round)
# round_ciphertexts = []
# for i in range(2):
#     p = Party.parties[i]
#     p.encode_model()
#     ctxs = p.encrypt_model()
#     round_ciphertexts.append(ctxs)
# # print(ctxss[0][0])
# ctx_total = [evaluator.add_many([ciphertext[i] for ciphertext in round_ciphertexts]) for i in range(len(round_ciphertexts[0]))]
# decrypt = p.decrypt_model(ctx_total)
# # print(decrypt)
#     # decrypt=None
# sum_state = p.decode_model(decrypt)
# load_model(sum_state,global_model)
# print(len(Party.parties[0].images))

# print(list(Party.parties[1].model.parameters())[0]*2-list(global_model.parameters())[0])
total_train(10)